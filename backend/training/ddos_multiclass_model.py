# -*- coding: utf-8 -*-
"""ddos_multiclass_model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FiZ8dYTAbiPxWCIJI5VVyYQUJXZiHs9t
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#!/usr/bin/env python3
"""
multiclass_ddos_final_dynamic.py
──────────────────────────────────────────────────────────
7 Attack + BENIGN (8-class) 다중분류 – 열이 달라도 자동 적응
"""

import os, gc, argparse, json, logging, warnings
from pathlib import Path
import numpy as np, pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing  import StandardScaler, LabelEncoder
from sklearn.metrics        import classification_report, confusion_matrix
from sklearn.ensemble       import VotingClassifier
from xgboost                import XGBClassifier
from lightgbm               import LGBMClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling  import SMOTE
import matplotlib; matplotlib.use("Agg")
import matplotlib.pyplot as plt, seaborn as sns
import joblib

# ────────── 설정
warnings.filterwarnings("ignore")
logging.basicConfig(level=logging.INFO,
                    format="%(asctime)s | %(levelname)s | %(message)s")
log = logging.getLogger(__name__)

BASE_DEF, OUT_DEF = "/content/drive/MyDrive/CSV-03-11/Datasets", "ddos_mc_final"
CHUNK, UNDER, SMOTE_K, TEST_RATIO, RAND = 2_000, 0.3, 3, 0.2, 42
ATTACKS = ["UDP","UDPLAG","SYN","PORTMAP","NETBIOS","MSSQL","LDAP"]

# 후보 피처 ↔ 자주 쓰이는 약어 매핑
FEAT_CANON = {
    "flowduration":               ["Flow Duration"],
    "totfwdpkts":                 ["Total Fwd Packets","Tot Fwd Pkts"],
    "totbwdpkts":                 ["Total Backward Packets","Tot Bwd Pkts"],
    "flowiatmean":                ["Flow IAT Mean"],
    "flowiatstd":                 ["Flow IAT Std"],
    "fwdpktlenmean":              ["Fwd Packet Length Mean"],
    "bwdpktlenmean":              ["Bwd Packet Length Mean"],
    "fwdpktlenstd":               ["Fwd Packet Length Std"],
    "bwdpktlenstd":               ["Bwd Packet Length Std"],
    "avgpktsize":                 ["Average Packet Size"],
    "totfwdb":                    ["Total Fwd Bytes","TotLen Fwd Pkts"],
    "totbwdb":                    ["Total Bwd Bytes","TotLen Bwd Pkts"]
}

# ────────── 경로 보조
def find_dir(user: str|None) -> str:
    if user and Path(user).exists(): return user
    for p in (BASE_DEF, "./Datasets", "./data", "."):
        if Path(p).exists() and any(Path(p).rglob("*.csv")): return str(p)
    raise FileNotFoundError("CSV 폴더를 찾지 못했습니다.")

def tag(fp: str) -> str:
    name = Path(fp).stem.upper()
    if "BENIGN" in name: return "BENIGN"
    for atk in ATTACKS:
        if atk in name: return atk
    return name

# ────────── 1. 데이터 로드
def load_dataset(base: str):
    frames, canon_used = [], {}
    for fp in Path(base).rglob("*.csv*"):
        ftag = tag(fp)
        for chunk in pd.read_csv(fp, chunksize=CHUNK, low_memory=False):
            chunk.columns = [c.strip() for c in chunk.columns]
            # 현재 청크 컬럼을 정규화 키(소문자·공백삭제)로 변환
            norm = {c.lower().replace(" ", ""): c for c in chunk.columns}

            # 이번 청크에서 사용할 실제 컬럼 이름 리스트
            cols = []
            for key, aliases in FEAT_CANON.items():
                for alias in aliases:
                    alias_key = alias.lower().replace(" ", "")
                    if alias_key in norm:
                        cols.append(norm[alias_key])
                        canon_used[key] = norm[alias_key]
                        break  # 첫 매칭만

            if not cols: continue

            if "Label" in chunk.columns:
                chunk["Label"] = chunk["Label"].astype(str).str.strip().str.upper()
            else:
                chunk["Label"] = ftag

            if ftag == "BENIGN":
                sub = chunk[cols].copy(); sub["Label"] = "BENIGN"
            else:
                sub = chunk[(chunk["Label"]=="BENIGN")|(chunk["Label"]==ftag)][cols+["Label"]]

            sub = (sub.replace([np.inf,-np.inf],np.nan)
                     .dropna()
                     .loc[lambda d: (d[cols]>=0).all(axis=1)])
            if len(sub):
                frames.append(sub)
        gc.collect()

    if not frames: raise ValueError("유효 데이터가 없습니다.")
    df = pd.concat(frames, ignore_index=True)
    used_feat = [canon_used[k] for k in FEAT_CANON if k in canon_used]
    log.info("로드 %,d 행 · 사용 피처 %s", len(df), used_feat)
    return df, used_feat

# ────────── 2. 밸런싱
def rebalance(df, feats, use_smote):
    X, y = df[feats], df["Label"]
    vc = y.value_counts()
    max_allowed = int(vc.min() / UNDER)
    strategy = {cls: min(cnt, max_allowed) for cls, cnt in vc.items()}
    rus = RandomUnderSampler(sampling_strategy=strategy, random_state=RAND)
    X_r, y_r = rus.fit_resample(X, y)

    if use_smote:
        sm = SMOTE(k_neighbors=max(1, min(y_r.value_counts())-1),
                   random_state=RAND)
        X_s, y_s = sm.fit_resample(X_r, y_r)
        df_bal = pd.DataFrame(X_s, columns=feats); df_bal["Label"] = y_s
    else:
        df_bal = pd.DataFrame(X_r, columns=feats); df_bal["Label"] = y_r
    return df_bal

# ────────── 3. 모델
def ensemble(n_cls):
    lgb = LGBMClassifier(objective="multiclass", num_class=n_cls,
                         n_estimators=80, learning_rate=0.07, max_depth=7,
                         subsample=0.8, colsample_bytree=0.8,
                         class_weight="balanced", random_state=RAND, n_jobs=-1)
    xgb = XGBClassifier(objective="multi:softprob", num_class=n_cls,
                        n_estimators=80, learning_rate=0.07, max_depth=7,
                        subsample=0.8, colsample_bytree=0.8,
                        random_state=RAND, n_jobs=-1,
                        eval_metric="mlogloss", use_label_encoder=False)
    return VotingClassifier([("lgb", lgb), ("xgb", xgb)], voting="soft", n_jobs=-1)

# ────────── 시각화 & 저장
def plot_cm(cm, classes, path: Path):
    plt.figure(figsize=(6,4.5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=classes, yticklabels=classes)
    plt.xlabel("Predicted"); plt.ylabel("True")
    plt.tight_layout(); plt.savefig(path, dpi=150); plt.close()

def save_artifacts(model, scaler, enc, feats, out: Path):
    joblib.dump(model,  out/"model.pkl")
    joblib.dump(scaler, out/"scaler.pkl")
    joblib.dump(enc,    out/"encoder.pkl")
    (out/"features.txt").write_text("\n".join(feats))

# ────────── main
def main():
    ap = argparse.ArgumentParser("Multiclass DDoS (Dynamic Feature)")
    ap.add_argument("--data_dir",   default=None)
    ap.add_argument("--output_dir", default=OUT_DEF)
    ap.add_argument("--use_smote",  action="store_true")
    args, _ = ap.parse_known_args()

    base         = find_dir(args.data_dir)
    df_raw, feats= load_dataset(base)
    df_bal       = rebalance(df_raw, feats, args.use_smote)

    X = df_bal[feats].astype(np.float32).values
    enc = LabelEncoder().fit(df_bal["Label"]); y = enc.transform(df_bal["Label"])
    X_tr, X_te, y_tr, y_te = train_test_split(
        X, y, test_size=TEST_RATIO, stratify=y, random_state=RAND)
    scaler = StandardScaler().fit(X_tr)
    model  = ensemble(len(enc.classes_)); model.fit(scaler.transform(X_tr), y_tr)

    y_pred = model.predict(scaler.transform(X_te))
    print("\n" + "="*55); print("다중분류 결과")
    print(classification_report(y_te, y_pred, target_names=enc.classes_, digits=4))

    out = Path(args.output_dir); out.mkdir(exist_ok=True)
    plot_cm(confusion_matrix(y_te, y_pred), enc.classes_, out/"confusion_matrix.png")
    json.dump(classification_report(y_te, y_pred, target_names=enc.classes_,
                                    digits=4, output_dict=True),
              open(out/"report.json","w"), indent=2)
    save_artifacts(model, scaler, enc, feats, out)
    log.info("완료 ✔  산출물: %s", out.resolve())

if __name__ == "__main__":
    main()

import joblib, pathlib, json, os

base = pathlib.Path("ddos_mc_final")

# 1) 모델 파일 이름 변경(복사)
(src := base/"model.pkl").replace(base/"ddos_multiclass_model.pkl")

# 2) 클래스 목록 TXT로 추출
enc = joblib.load(base/"encoder.pkl")
with open(base/"ddos_label_classes.txt", "w") as f:
    f.write("\n".join(enc.classes_))

print("✅ 파일 두 개가 생성되었습니다:")
print("  - ddos_multiclass_model.pkl")
print("  - ddos_label_classes.txt")